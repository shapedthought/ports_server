{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1720537360401,
     "user": {
      "displayName": "Ed Howard (Mr X)",
      "userId": "07534693404549688478"
     },
     "user_tz": -60
    },
    "id": "CwoONobPZS16"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import io\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configuration.json\") as config_file:\n",
    "    config = json.load(config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the URLS for each of the port pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_vbo = \"https://helpcenter.veeam.com/docs/vbo365/guide/vbo_used_ports.html\"\n",
    "url_vbr = \"https://helpcenter.veeam.com/docs/backup/vsphere/used_ports.html\"\n",
    "url_hyperv = \"https://helpcenter.veeam.com/docs/backup/hyperv/used_ports.html\"\n",
    "url_ahv = \"https://helpcenter.veeam.com/docs/vbahv/userguide/used_ports.html\"\n",
    "url_olvm_rhel = \"https://helpcenter.veeam.com/docs/vbrhv/userguide/used_ports.html\"\n",
    "url_proxmox = \"https://helpcenter.veeam.com/docs/vbproxmoxve/userguide/used_ports.html\"\n",
    "url_vcc = \"https://helpcenter.veeam.com/docs/backup/cloud/ports.html\"\n",
    "url_vro = \"https://helpcenter.veeam.com/docs/vro/userguide/ports.html\"\n",
    "\n",
    "url_vbaws = \"https://helpcenter.veeam.com/docs/vbaws/guide/ports.html\"\n",
    "url_vbaz = \"https://helpcenter.veeam.com/docs/vbazure/guide/ports.html\"\n",
    "url_gcp = \"https://helpcenter.veeam.com/docs/vbgc/guide/ports.html\"\n",
    "url_windows = \"https://helpcenter.veeam.com/docs/agentforwindows/userguide/ports.html\"\n",
    "url_linux = \"https://helpcenter.veeam.com/docs/agentforlinux/userguide/used_ports.html\"\n",
    "url_agent_man = \"https://helpcenter.veeam.com/docs/backup/agents/used_ports.html\"\n",
    "url_vone = \"https://helpcenter.veeam.com/docs/one/deployment/ports.html\"\n",
    "url_vspc = \"https://helpcenter.veeam.com/docs/vac/deployment/ports.html\"\n",
    "\n",
    "url_explore_ad = \"https://helpcenter.veeam.com/docs/backup/explorers/vead_ports.html\"\n",
    "url_explore_sql = (\n",
    "    \"https://helpcenter.veeam.com/docs/backup/explorers/vesql_used_ports.html\"\n",
    ")\n",
    "url_explore_orcle = (\n",
    "    \"https://helpcenter.veeam.com/docs/backup/explorers/veo_used_ports.html\"\n",
    ")\n",
    "url_explore_postgres = (\n",
    "    \"https://helpcenter.veeam.com/docs/backup/explorers/vep_used_ports.html\"\n",
    ")\n",
    "url_explore_saphana = (\n",
    "    \"https://helpcenter.veeam.com/docs/backup/explorers/vemdb_used_ports.html\"\n",
    ")\n",
    "url_explore_mongo = (\n",
    "    \"https://helpcenter.veeam.com/docs/backup/explorers/vemdb_used_ports.html\"\n",
    ")\n",
    "\n",
    "url_explore_exchange = (\n",
    "    \"https://helpcenter.veeam.com/docs/backup/explorers/vex_ports.html\"\n",
    ")\n",
    "url_explore_sharepoint = (\n",
    "    \"https://helpcenter.veeam.com/docs/backup/explorers/vesp_ports.html\"\n",
    ")\n",
    "\n",
    "url_list = [\n",
    "    url_vbo,\n",
    "    url_vbr,\n",
    "    url_vbaws,\n",
    "    url_vbaz,\n",
    "    url_gcp,\n",
    "    url_windows,\n",
    "    url_linux,\n",
    "    url_agent_man,\n",
    "    url_vspc,\n",
    "    url_explore_ad,\n",
    "    url_explore_sql,\n",
    "    url_explore_orcle,\n",
    "    url_explore_postgres,\n",
    "    url_explore_saphana,\n",
    "    url_explore_mongo,\n",
    "    url_explore_exchange,\n",
    "    url_explore_sharepoint,\n",
    "]\n",
    "\n",
    "len(url_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to handle the HTML to DataFrame conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def html_to_dataframe2(url, product):\n",
    "    html = requests.get(url)\n",
    "    soup = BeautifulSoup(html.content, \"html.parser\")\n",
    "\n",
    "    # Extract tables\n",
    "    tables = pd.read_html(io.StringIO(html.text))\n",
    "\n",
    "    # Extract headings in document order\n",
    "    all_headings = []\n",
    "    current_main_heading = None\n",
    "\n",
    "    # Find all heading elements in order of appearance\n",
    "    if product != \"VCC\":\n",
    "        for element in soup.body.find_all([\"span\"]):\n",
    "            if \"class\" in element.attrs:\n",
    "                element_classes = element.get(\"class\", [])\n",
    "\n",
    "                if (\n",
    "                    \"Subheading\" in element_classes\n",
    "                    and \"Subheading_L2\" not in element_classes\n",
    "                ):\n",
    "                    # Main heading found\n",
    "                    current_main_heading = element.text.strip()\n",
    "                    all_headings.append(\n",
    "                        {\n",
    "                            \"text\": current_main_heading,\n",
    "                            \"type\": \"main\",\n",
    "                            \"position\": len(all_headings),\n",
    "                            \"combined\": current_main_heading,\n",
    "                        }\n",
    "                    )\n",
    "                elif \"Subheading_L2\" in element_classes and current_main_heading:\n",
    "                    # Subheading found\n",
    "                    subheading_text = element.text.strip()\n",
    "                    combined_text = f\"{current_main_heading} - {subheading_text}\"\n",
    "                    all_headings.append(\n",
    "                        {\n",
    "                            \"text\": subheading_text,\n",
    "                            \"type\": \"sub\",\n",
    "                            \"position\": len(all_headings),\n",
    "                            \"combined\": combined_text,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "    # Process each table from the HTML\n",
    "    processed_tables = []\n",
    "    current_heading_idx = 0\n",
    "\n",
    "    for table in tables:\n",
    "        if product == \"VONE\":\n",
    "            # For VONE, we need to handle the table differently\n",
    "            # Check if the table has a 'From' and 'To' column\n",
    "            table[\"Section\"] = np.where(\n",
    "                table[\"From\"] == table[\"To\"], table[\"From\"], np.nan\n",
    "            )\n",
    "            table[\"Section\"] = table[\"Section\"].ffill()\n",
    "        else:\n",
    "            # Only process tables with more than 1 column (to avoid irrelevant tables)\n",
    "            if len(table.columns) > 1:\n",
    "                # Check if we have headings to use\n",
    "                if len(all_headings) > 0 and current_heading_idx < len(all_headings):\n",
    "                    heading_info = all_headings[current_heading_idx]\n",
    "                    table[\"Section\"] = heading_info[\"combined\"]\n",
    "                    current_heading_idx += 1\n",
    "                else:\n",
    "                    # If we don't have headings, try to extract sections from the table itself\n",
    "                    # If there's a 'From' column, check for common values that might indicate sections\n",
    "                    if \"From\" in table.columns:\n",
    "                        # Find groups of rows with the same 'From' value\n",
    "                        section_groups = []\n",
    "                        current_section = None\n",
    "                        section_rows = []\n",
    "\n",
    "                        for idx, row in table.iterrows():\n",
    "                            if pd.notna(row[\"From\"]):\n",
    "                                if current_section != row[\"From\"]:\n",
    "                                    # New section found\n",
    "                                    if current_section is not None and section_rows:\n",
    "                                        section_groups.append(\n",
    "                                            (current_section, section_rows)\n",
    "                                        )\n",
    "                                        section_rows = []\n",
    "                                    current_section = row[\"From\"]\n",
    "                                section_rows.append(idx)\n",
    "\n",
    "                        # Add the last section group if exists\n",
    "                        if current_section is not None and section_rows:\n",
    "                            section_groups.append((current_section, section_rows))\n",
    "\n",
    "                        # Apply sections to the table\n",
    "                        for section_name, row_indices in section_groups:\n",
    "                            table.loc[row_indices, \"Section\"] = section_name\n",
    "\n",
    "                        # If any rows didn't get a section, use the first non-empty From value\n",
    "                        if table[\"Section\"].isna().any():\n",
    "                            from_values = table[\"From\"].dropna().unique()\n",
    "                            if len(from_values) > 0:\n",
    "                                table[\"Section\"] = table[\"Section\"].fillna(\n",
    "                                    from_values[0]\n",
    "                                )\n",
    "                            else:\n",
    "                                table[\"Section\"] = table[\"Section\"].fillna(\n",
    "                                    \"Unknown Section\"\n",
    "                                )\n",
    "                    else:\n",
    "                        # No From column, use a default section\n",
    "                        table[\"Section\"] = \"Unknown Section\"\n",
    "\n",
    "        # Add product information\n",
    "        table[\"Product\"] = product\n",
    "\n",
    "        processed_tables.append(table)\n",
    "\n",
    "    if not processed_tables:\n",
    "        return pd.DataFrame()  # Return empty DataFrame if no tables processed\n",
    "\n",
    "    # Combine all processed tables\n",
    "    df = pd.concat(processed_tables, ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_to_dataframe(url, product):\n",
    "    html = requests.get(url)\n",
    "    df = pd.read_html(io.StringIO(html.text))\n",
    "    df = pd.concat(df)\n",
    "    df[\"Product\"] = product\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = html_to_dataframe2(url_vone, \"VONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the function on all the URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3818,
     "status": "ok",
     "timestamp": 1720537364622,
     "user": {
      "displayName": "Ed Howard (Mr X)",
      "userId": "07534693404549688478"
     },
     "user_tz": -60
    },
    "id": "2TkyXIv1ZY4l"
   },
   "outputs": [],
   "source": [
    "df_vbo = html_to_dataframe2(url_vbo, \"VB365\")\n",
    "df_vbr = html_to_dataframe2(url_vbr, \"VBR\")\n",
    "df_vbr_hyperv = html_to_dataframe2(url_hyperv, \"VBR Hyper-V\")\n",
    "df_ahv = html_to_dataframe2(url_ahv, \"AHV\")\n",
    "df_url_olvm = html_to_dataframe2(url_olvm_rhel, \"OLVM / RHV\")\n",
    "df_proxmox = html_to_dataframe2(url_proxmox, \"Proxmox\")\n",
    "df_vro = html_to_dataframe2(url_vro, \"VRO\")\n",
    "\n",
    "df_vbaws = html_to_dataframe2(url_vbaws, \"VBAWS\")\n",
    "df_vbaz = html_to_dataframe2(url_vbaz, \"VBAZ\")\n",
    "df_gcp = html_to_dataframe2(url_gcp, \"VBGCP\")\n",
    "\n",
    "df_windows = html_to_dataframe2(url_windows, \"Windows\")\n",
    "df_agent_man = html_to_dataframe2(url_agent_man, \"Agent Management\")\n",
    "df_linux = html_to_dataframe2(url_linux, \"Linux\")\n",
    "\n",
    "df_vone = html_to_dataframe2(url_vone, \"VONE\")\n",
    "\n",
    "df_vspc = html_to_dataframe2(url_vspc, \"VSPC\")\n",
    "df_vcc = html_to_dataframe2(url_vcc, \"VCC\")\n",
    "\n",
    "df_explorer_ad = html_to_dataframe2(url_explore_ad, \"Explorer AD\")\n",
    "df_explorer_sql = html_to_dataframe2(url_explore_sql, \"Explorer SQL\")\n",
    "df_explorer_orcle = html_to_dataframe2(url_explore_orcle, \"Explorer Oracle\")\n",
    "df_explorer_postgres = html_to_dataframe2(url_explore_postgres, \"Explorer Postgres\")\n",
    "df_explorer_saphana = html_to_dataframe2(url_explore_saphana, \"Explorer SAP HANA\")\n",
    "df_explorer_mongo = html_to_dataframe2(url_explore_mongo, \"Explorer Mongo\")\n",
    "df_explorer_exchange = html_to_dataframe2(url_explore_exchange, \"Explorer Exchange\")\n",
    "df_explorer_sharepoint = html_to_dataframe2(\n",
    "    url_explore_sharepoint, \"Explorer SharePoint\"\n",
    ")\n",
    "# OneDrive needs the SharePoint ports\n",
    "# Teams needs the SharePoint and Exchange ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = [\n",
    "    df_vbo,\n",
    "    df_vbr,\n",
    "    df_vbr_hyperv,\n",
    "    df_ahv,\n",
    "    df_url_olvm,\n",
    "    df_proxmox,\n",
    "    df_vro,\n",
    "    df_vbaws,\n",
    "    df_vbaz,\n",
    "    df_gcp,\n",
    "    df_windows,\n",
    "    df_agent_man,\n",
    "    df_linux,\n",
    "    df_vone,\n",
    "    df_vspc,\n",
    "    df_vcc,\n",
    "    df_explorer_ad,\n",
    "    df_explorer_sql,\n",
    "    df_explorer_orcle,\n",
    "    df_explorer_postgres,\n",
    "    df_explorer_saphana,\n",
    "    df_explorer_mongo,\n",
    "    df_explorer_exchange,\n",
    "    df_explorer_sharepoint,\n",
    "]\n",
    "\n",
    "len(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatinate all the DataFrames into a single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1720537364623,
     "user": {
      "displayName": "Ed Howard (Mr X)",
      "userId": "07534693404549688478"
     },
     "user_tz": -60
    },
    "id": "2kXYZz6O_fho"
   },
   "outputs": [],
   "source": [
    "combined_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the Notes and Description columns into a single column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1720537364623,
     "user": {
      "displayName": "Ed Howard (Mr X)",
      "userId": "07534693404549688478"
     },
     "user_tz": -60
    },
    "id": "0rtQ98GpE559"
   },
   "outputs": [],
   "source": [
    "combined_df[\"Description\"] = np.where(\n",
    "    combined_df[\"Notes\"].notna(), combined_df[\"Notes\"], combined_df[\"Description\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"Description\"] = combined_df[\"Description\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the first and last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1720537364623,
     "user": {
      "displayName": "Ed Howard (Mr X)",
      "userId": "07534693404549688478"
     },
     "user_tz": -60
    },
    "id": "6ZoAXbEXZiUR"
   },
   "outputs": [],
   "source": [
    "combined_df.drop(columns=[0, combined_df.columns[-1]], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.drop(columns=[\"Notes\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all the NaN rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1720537364623,
     "user": {
      "displayName": "Ed Howard (Mr X)",
      "userId": "07534693404549688478"
     },
     "user_tz": -60
    },
    "id": "0e93m0enZy95"
   },
   "outputs": [],
   "source": [
    "combined_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove some unneeded rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df[combined_df[\"To\"] != \"Other Communications\"]\n",
    "combined_df = combined_df[\n",
    "    combined_df[\"To\"] != \"Communication with Virtualization Servers\"\n",
    "]\n",
    "combined_df = combined_df[combined_df[\"To\"] != \"Communication with Backup Server\"]\n",
    "combined_df = combined_df[\n",
    "    combined_df[\"To\"] != \"Communication with Backup Infrastructure Components\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace some hex values with their actual symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.replace(\"â\\x80\\x94\", \"—\", regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.replace(\"Â\\xa0\", \" \", regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check they have been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_df[combined_df[\"Description\"].str.contains(r\"Â\\xa0\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_df[combined_df[\"Description\"].str.contains(r\"Â\\xa0BackupÂ\\xa0&Â\\xa0\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_df[combined_df[\"To\"].str.contains(r\"Â\\xa0BackupÂ\\xa0&Â\\xa0\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1720537364623,
     "user": {
      "displayName": "Ed Howard (Mr X)",
      "userId": "07534693404549688478"
     },
     "user_tz": -60
    },
    "id": "Nc8Ts6sebmAc"
   },
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"allports.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1720537364623,
     "user": {
      "displayName": "Ed Howard (Mr X)",
      "userId": "07534693404549688478"
     },
     "user_tz": -60
    },
    "id": "s2BAW_QQbpMr"
   },
   "outputs": [],
   "source": [
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1720537364624,
     "user": {
      "displayName": "Ed Howard (Mr X)",
      "userId": "07534693404549688478"
     },
     "user_tz": -60
    },
    "id": "gdI4tukUbuIz",
    "outputId": "896b03c4-47c6-4202-efc1-f20f23140c28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1f6ac4b7bc0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\n",
    "    \"CREATE TABLE IF NOT EXISTS all_ports(product TEXT, section TEXT, from_port TEXT, to_port TEXT, protocol TEXT, port TEXT, description TEXT)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1720537364624,
     "user": {
      "displayName": "Ed Howard (Mr X)",
      "userId": "07534693404549688478"
     },
     "user_tz": -60
    },
    "id": "wIiUH960bunC"
   },
   "outputs": [],
   "source": [
    "for row in combined_df.itertuples(index=False):\n",
    "    cur.execute(\n",
    "        \"INSERT INTO all_ports VALUES(?, ?, ?, ?, ?, ?, ?)\",\n",
    "        (\n",
    "            str(row[0]),\n",
    "            str(row[6]),\n",
    "            str(row[1]),\n",
    "            str(row[2]),\n",
    "            str(row[3]),\n",
    "            str(row[4]),\n",
    "            str(row[5]),\n",
    "        ),\n",
    "    )\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run some checks to ensure it is all working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1720537364624,
     "user": {
      "displayName": "Ed Howard (Mr X)",
      "userId": "07534693404549688478"
     },
     "user_tz": -60
    },
    "id": "7eoqhUaxmN8f",
    "outputId": "9b80f014-ca33-4301-d8cf-b71a59f2924e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VB365\n",
      "VBR\n",
      "VBR Hyper-V\n",
      "AHV\n",
      "OLVM / RHV\n",
      "Proxmox\n",
      "VRO\n",
      "VBAWS\n",
      "VBAZ\n",
      "VBGCP\n",
      "Windows\n",
      "Agent Management\n",
      "Linux\n",
      "VONE\n",
      "VSPC\n",
      "VCC\n",
      "Explorer AD\n",
      "Explorer SQL\n",
      "Explorer Oracle\n",
      "Explorer Postgres\n",
      "Explorer SAP HANA\n",
      "Explorer Mongo\n",
      "Explorer Exchange\n",
      "Explorer SharePoint\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SELECT DISTINCT product FROM all_ports\")\n",
    "res = cur.fetchall()\n",
    "for r in res:\n",
    "    print(r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1720537364624,
     "user": {
      "displayName": "Ed Howard (Mr X)",
      "userId": "07534693404549688478"
     },
     "user_tz": -60
    },
    "id": "zl0LItvve6Bc",
    "outputId": "d9ea2cc9-5a6a-4111-ed4b-2b48495c4dd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9191\n",
      "9193\n",
      "443\n",
      "80 or 443\n",
      "25 or 465 or 587\n",
      "22\n",
      "5432 (used by default)\n",
      "4222 (used by default)\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\n",
    "    \"SELECT DISTINCT port FROM all_ports WHERE product = 'VB365' AND from_port = 'Backup proxy server1' AND protocol = 'TCP'\"\n",
    ")\n",
    "res = cur.fetchall()\n",
    "for i in res:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1720537364625,
     "user": {
      "displayName": "Ed Howard (Mr X)",
      "userId": "07534693404549688478"
     },
     "user_tz": -60
    },
    "id": "q73cMKGrqaFv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"SELECT COUNT(*)FROM all_ports WHERE Product = 'Linux'\")\n",
    "res = cur.fetchall()\n",
    "res[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1f6ac4b7bc0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\n",
    "    'SELECT * FROM all_ports WHERE Product = \"VBR\" AND Description LIKE \"%Threat hunter%\"'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('VBR',\n",
       " 'Backup Server',\n",
       " 'Backup server',\n",
       " 'Veeam License Update Server',\n",
       " 'TCP',\n",
       " '443',\n",
       " 'Default port used to automatically update license from the Veeam License Update Server over HTTPS. Veeam Threat Hunter and Veeam Data Cloud Vault also require this communication to work properly.Veeam License Update Server endpoints:vbr.butler.veeam.comautolk.veeam.com')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPrxYwHSw6sRFpx41nWeGS0",
   "mount_file_id": "1yl9nGwzsLasyURBu0SWlyqR8h8klmoUB",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "virt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
